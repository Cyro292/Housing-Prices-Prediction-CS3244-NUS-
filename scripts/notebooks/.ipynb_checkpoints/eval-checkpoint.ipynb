{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2be1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation.py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    r2_score, \n",
    "    mean_squared_error, \n",
    "    mean_absolute_error, \n",
    "    median_absolute_error,\n",
    "    explained_variance_score\n",
    ")\n",
    "\n",
    "def evaluate_regression(y_true, y_pred, n_features=None):\n",
    "    \"\"\"\n",
    "    Evaluates regression predictions by calculating multiple metrics.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (array-like): True target values.\n",
    "        y_pred (array-like): Predicted target values.\n",
    "        n_features (int, optional): Number of features used in the model. \n",
    "            If provided, the function computes the Adjusted R².\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - R2: R-squared score.\n",
    "            - Adjusted_R2: Adjusted R-squared score (if n_features provided).\n",
    "            - ExplainedVariance: Explained Variance Score.\n",
    "            - RMSE: Root Mean Squared Error.\n",
    "            - MAE: Mean Absolute Error.\n",
    "            - MAPE: Mean Absolute Percentage Error (percentage).\n",
    "            - MedianAE: Median Absolute Error.\n",
    "            - Residuals: The differences (y_true - y_pred).\n",
    "    \"\"\"\n",
    "    # Basic metrics\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    median_ae = median_absolute_error(y_true, y_pred)\n",
    "    evs = explained_variance_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate MAPE with safe division (replace zeros in y_true with 1)\n",
    "    y_true_safe = np.where(np.array(y_true)==0, 1, np.array(y_true))\n",
    "    mape = np.mean(np.abs((np.array(y_true) - np.array(y_pred)) / y_true_safe)) * 100\n",
    "    \n",
    "    # Residuals for further analysis\n",
    "    residuals = np.array(y_true) - np.array(y_pred)\n",
    "    \n",
    "    # Compute adjusted R2 if number of features is provided\n",
    "    adjusted_r2 = None\n",
    "    n = len(y_true)\n",
    "    if n_features is not None and n > n_features + 1:\n",
    "        adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - n_features - 1)\n",
    "    \n",
    "    metrics = {\n",
    "        \"R2\": r2,\n",
    "        \"Adjusted_R2\": adjusted_r2,\n",
    "        \"ExplainedVariance\": evs,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"MAPE\": mape,\n",
    "        \"MedianAE\": median_ae,\n",
    "        \"Residuals\": residuals\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Test the function if the module is run directly.\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data for quick testing.\n",
    "    y_true = np.array([3, -0.5, 2, 7])\n",
    "    y_pred = np.array([2.5, 0.0, 2, 8])\n",
    "    # Let's assume our model used 2 features for adjusted R² calculation.\n",
    "    results = evaluate_regression(y_true, y_pred, n_features=2)\n",
    "    print(\"Enhanced Evaluation Metrics:\")\n",
    "    for key, value in results.items():\n",
    "        if key != \"Residuals\":\n",
    "            print(f\"{key}: {value}\")\n",
    "    print(\"Residuals:\", results[\"Residuals\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
