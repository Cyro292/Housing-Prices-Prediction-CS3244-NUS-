{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from lib.utils import get_train_split_data, load_all_resale_data, get_cleaned_normalized_data, get_feature_optimised_data\n",
    "from lib.eval import get_regression_metrics\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/amonsisowath/VSC/Uni/Sing2425/CS3244/Assignment1/scripts/lib/../data/Resale Flat Prices (Based on Approval Date), 1990 - 1999.csv...\n",
      "Loading data from /Users/amonsisowath/VSC/Uni/Sing2425/CS3244/Assignment1/scripts/lib/../data/Resale Flat Prices (Based on Approval Date), 2000 - Feb 2012.csv...\n",
      "Loading data from /Users/amonsisowath/VSC/Uni/Sing2425/CS3244/Assignment1/scripts/lib/../data/Resale Flat Prices (Based on Registration Date), From Mar 2012 to Dec 2014.csv...\n",
      "Loading data from /Users/amonsisowath/VSC/Uni/Sing2425/CS3244/Assignment1/scripts/lib/../data/Resale Flat Prices (Based on Registration Date), From Jan 2015 to Dec 2016.csv...\n",
      "Loading data from /Users/amonsisowath/VSC/Uni/Sing2425/CS3244/Assignment1/scripts/lib/../data/Resale flat prices based on registration date from Jan-2017 onwards.csv...\n",
      "Combined dataset shape: (948962, 11)\n",
      "Features shape: (948962, 10)\n",
      "Target shape: (948962,)\n",
      "Selected features: month, town, flat_type, block, street_name, storey_range, floor_area_sqm, flat_model, lease_commence_date, remaining_lease\n",
      "Found 279 NaN values after processing. Handling them...\n",
      "Loading resale flat price data...\n",
      "X_train shape: (189792, 2800)\n",
      "X_test shape: (759170, 2800)\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "X, y = load_all_resale_data()\n",
    "X, y = get_cleaned_normalized_data(X, y)\n",
    "X_opt, Y_opt = get_feature_optimised_data(X, y)\n",
    "X_train, X_test, y_train, y_test = get_train_split_data(X, y, 0.2)\n",
    "X_opt_train, X_opt_test, y_opt_train, y_opt_test = get_train_split_data(X_opt, Y_opt, 0.2)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial degree 1:\n",
      "  Training R²: 0.8498, Test R²: 0.8491\n",
      "  Gap: 0.0006\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 2. Test different polynomial degrees to check for underfitting/overfitting\n",
    "degrees = [1, 2, 3, 5]\n",
    "train_rmse_list = []\n",
    "test_rmse_list = []\n",
    "train_r2_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "for degree in degrees:\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_opt_train)\n",
    "    X_test_poly = poly.transform(X_opt_test)\n",
    "    \n",
    "    # Train model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_opt_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train_poly)\n",
    "    y_pred_test = model.predict(X_test_poly)\n",
    "    \n",
    "    # Calculate errors\n",
    "    train_r2 = get_regression_metrics(y_opt_train, y_pred_train)['r2']\n",
    "    test_r2 = get_regression_metrics(y_opt_test, y_pred_test)['r2']\n",
    "\n",
    "    train_r2_list.append(train_r2)\n",
    "    test_r2_list.append(test_r2)\n",
    "    \n",
    "    print(f\"Polynomial degree {degree}:\")\n",
    "    print(f\"  Training R²: {train_r2:.4f}, Test R²: {test_r2:.4f}\")\n",
    "    print(f\"  Gap: {train_r2 - test_r2:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results to visualize overfitting/underfitting\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(degrees, train_rmse_list, 'o-', label='Training RMSE')\n",
    "plt.plot(degrees, test_rmse_list, 'o-', label='Test RMSE')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE vs Polynomial Degree')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(degrees, train_r2_list, 'o-', label='Training R²')\n",
    "plt.plot(degrees, test_r2_list, 'o-', label='Test R²')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('R² vs Polynomial Degree')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualize the \"sweet spot\" between underfitting and overfitting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(degrees, np.array(train_r2_list) - np.array(test_r2_list), 'o-', linewidth=2)\n",
    "plt.axhline(y=0.05, color='r', linestyle='--', alpha=0.7)\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('R² Gap (Training - Test)')\n",
    "plt.title('Overfitting Indicator: Training vs Test Performance Gap')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.annotate('Acceptable Region', xy=(1, 0.02), xytext=(2, 0.02), \n",
    "             arrowprops=dict(arrowstyle='->'), color='darkgreen')\n",
    "plt.show()\n",
    "\n",
    "# Find the optimal degree (smallest gap with good performance)\n",
    "gaps = np.array(train_r2_list) - np.array(test_r2_list)\n",
    "performance = np.array(test_r2_list)\n",
    "\n",
    "# Consider models with gap < 0.1 and sort by test performance\n",
    "good_models = [(deg, gap, perf) for deg, gap, perf in zip(degrees, gaps, performance) if gap < 0.1]\n",
    "if good_models:\n",
    "    good_models.sort(key=lambda x: x[2], reverse=True)\n",
    "    best_degree = good_models[0][0]\n",
    "    print(f\"Recommended polynomial degree: {best_degree}\")\n",
    "    print(f\"This gives test R² of {good_models[0][2]:.4f} with a gap of {good_models[0][1]:.4f}\")\n",
    "else:\n",
    "    print(\"All models show significant overfitting. Consider regularization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Check for potential outliers and their impact on the model\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "# Train regularized models\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "lasso = Lasso(alpha=0.01)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "\n",
    "# Get predictions from our baseline model again for comparison\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals_linear = y_test - y_pred_linear\n",
    "residuals_ridge = y_test - y_pred_ridge\n",
    "residuals_lasso = y_test - y_pred_lasso\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(y_pred_linear, residuals_linear, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('Linear Model Residuals')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(y_pred_ridge, residuals_ridge, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('Ridge Model Residuals')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(y_pred_lasso, residuals_lasso, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('Lasso Model Residuals')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate regression metrics for all models\n",
    "metrics_linear = get_regression_metrics(y_test, y_pred_linear)\n",
    "metrics_ridge = get_regression_metrics(y_test, y_pred_ridge)\n",
    "metrics_lasso = get_regression_metrics(y_test, y_pred_lasso)\n",
    "\n",
    "print(\"Metrics comparison:\")\n",
    "print(f\"Linear - R²: {metrics_linear['r2']:.4f}, RMSE: {metrics_linear['rmse']:.2f}\")\n",
    "print(f\"Ridge  - R²: {metrics_ridge['r2']:.4f}, RMSE: {metrics_ridge['rmse']:.2f}\")\n",
    "print(f\"Lasso  - R²: {metrics_lasso['r2']:.4f}, RMSE: {metrics_lasso['rmse']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Conclusions and recommendations\n",
    "print(\"\\nConclusions:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Compare training and test performance\n",
    "if train_r2 - test_r2 > 0.1:\n",
    "    print(\"- Model shows signs of OVERFITTING (training R² much higher than test R²)\")\n",
    "    print(\"  Recommendations: Use regularization, reduce model complexity, or gather more data.\")\n",
    "elif test_r2 < 0.5:\n",
    "    print(\"- Model shows signs of UNDERFITTING (low R² score on both training and test)\")\n",
    "    print(\"  Recommendations: Increase model complexity, add more features, or use non-linear models.\")\n",
    "else:\n",
    "    print(\"- Model shows good balance between bias and variance.\")\n",
    "\n",
    "# Check if regularization helps\n",
    "if metrics_ridge['r2'] > metrics_linear['r2'] or metrics_lasso['r2'] > metrics_linear['r2']:\n",
    "    print(\"- Regularization improves the model, suggesting potential overfitting in the linear model.\")\n",
    "    \n",
    "    if metrics_ridge['r2'] > metrics_lasso['r2']:\n",
    "        print(\"  Ridge regularization works best, indicating many features contribute partially.\")\n",
    "    else:\n",
    "        print(\"  Lasso regularization works best, indicating sparse feature importance.\")\n",
    "\n",
    "# Final recommendations\n",
    "print(\"\\nFinal Recommendations:\")\n",
    "if good_models:\n",
    "    print(f\"- Use polynomial features with degree {best_degree} for best performance without overfitting.\")\n",
    "    \n",
    "if metrics_ridge['r2'] > metrics_linear['r2'] and metrics_ridge['r2'] > metrics_lasso['r2']:\n",
    "    print(\"- Use Ridge regularization to control model complexity.\")\n",
    "elif metrics_lasso['r2'] > metrics_linear['r2'] and metrics_lasso['r2'] >= metrics_ridge['r2']:\n",
    "    print(\"- Use Lasso regularization for feature selection and to control model complexity.\")\n",
    "    \n",
    "print(\"- Consider exploring ensemble methods or more sophisticated models if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best  degree seem to be 3 with accuracy reaching 94%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
